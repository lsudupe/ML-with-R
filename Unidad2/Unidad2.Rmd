---
title: "K-NN"
author: "Laura Sudupe Medinilla"
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
output:
  pdf_document:
    toc: yes
    toc_depth: 2
  html_document:
    toc: yes
    toc_depth: 2
    toc_float: yes
bibliography: scholar.bib
lang: en # language,  en: english (default), es: espa?ol, ca: catalan, ..
---

```{r setup, include=FALSE}
# knitr options
knitr::opts_chunk$set(echo = TRUE)

```

```{r libraries, include=FALSE}
# Install packages
# Load packages
# ...

library(knitr)
```

# Step 1

## Collect the data

```{r input, include=FALSE}
# Input / Output variables
# Tuning parameters
# ...
file1 <- "usedcars.csv"

```

# Step 2

## Exploring and preparing the data

Import the CSV data file to the `cancer_mama` dataframe.

```{r}
cancer_mama <- read.csv("wisc_bc_data.csv", stringsAsFactors = FALSE)
```

Using the `str(cancer_mama)`command, we can see the data structure. 

```{r}
str(cancer_mama)
```
We can see the stdy has `r ncol(cancer_mama)` examples and `r nrow(cancer_mama)`
features. The first feature `id` is a unique identifier for each patient in the data, we will
exclude it from the model.
```{r}
cancer_mama <- cancer_mama[-1]
```

The variable `diagnosis` is going to be our label, the oucome we hope to predict.
This feature indicates whether the exmaple is from a benign or malignant mass.
With the `r table()` output we can see that `r table(cancer_mama$diagnosis == 'B`)
are benign while `r table(cancer_mama$diagnosis == "M")` are malignant.
```{r}
table(cancer_mama$diagnosis)
```
Many R machine learning classifiers require the target feature is coded as a 
factor, so we will recode `diagnosis` feature.
```{r}
cancer_mama$diagnosis <- factor(cancer_mama$diagnosis, levels = c("B", "M"),
                                labels = c("Benign", "Malignant"))
```
Let´s check the `Benign` and `Malignant` percentages with `r prop.table()`
```{r}
round(prop.table(table(cancer_mama$diagnosi)) * 100, digits=1)
```
All the remaining features are numeric, they consist of three different 
measurements of ten characteristics. We will take a closser look of three of 
these features
```{r}
summary(cancer_mama[c("radius_mean", "area_mean", "smoothness_mean")])
```
The distance calculation for k-NN is heavily dependent upon the measurement 
sclae of the input features. Since `smoothness_mean` ranges from `r round(min(cancer_mama$smoothness_mean), 2)` 
to `r round(max(cancer_mama$smoothness_mean), 2)` and `area_mean` ranges from 
`r round(min(cancer_mama$area_mean), 2)` to `r round(max(cancer_mama$area_mean), 2)`,
the impact of area is going to be much larger than smoothness in the distance
calculation. This cpuld potentially cause problems for our classifier, so let´s
apply normalization to rescale the features to a standard range of values.

## Transformation - normalizing numeric data

To normalize these features, we need to create a `normalize()` function. 
```{r}
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}
```
The ´lapply()´ function take a list and applies a specified function to each list 
element. As a data frame is a list of equal-length vectors, we can use ´lapply()´
to apply ´normalize()´ to each feature in the data frame. The final step is to 
convert the list returned by `lapply()` to a data frame, using the ´as.data.frame()´
function
```{r}
cancer_mama_n <-as.data.frame(lapply(cancer_mama[2:31], normalize))
```
Check the transformation was applied correctly
```{r}
summary(cancer_mama_n[c("radius_mean", "area_mean", "smoothness_mean")])
```

## Data preparation - creating training and test datasets

We can simulate unkown label data by dividing our data into two portions: a
training dataset that will be used to build the k-NN model and a test dataset
that will be used to estimate the predictive accuracy of the model. We will use
the first 469 records for the training dataset and the remaining 100 to simulate
new patients.We can do these because the data is already randomly ordered.
```{r}
cancer_train <- cancer_mama_n[1:469,]
cancer_test <- cancer_mama_n[470:569,]
```

The next step is to exclude the target variable ´diagnosis´. For training the 
k--NN model, we will need to store these class labels in factor vectors, split 
between the training and test datasets
```{r}
cancer_train_labels <- cancer_mama[1:469, 1]
cancer_test_lables <- cancer_mama[470:569, 1]
```
With these code we create the vectors ´cancer_train_labels´ and ´cancer_test_labels´.
We will use these in the next steps of training and evaluating our classifier.

# Step 3

## Training a model on the data

For the k-NN algorithm, the training phase actually involves no model building; 
the process of training simply involves storing the input data in a structured 
format.

To classify our test instances, we will use a k-NN implementation from the ´r class´
package, which provides a set of basic R functions for classification. 

```{r}
#install.packages("class")
library("class")
```
The ´r knn()´ function in the ´r class´ package provides a standard, classic 
implementation of the k-NN algorithm. For each instance in the test data, the 
function will identify the K-Nearest Neighbors, using Eucledian distance, where 
*k* is a user-specified number. The test instance is classified by taking a "vote"
among the k-Neares Neighbors- specifically, this involves assigning the class of
the majority of the *k* neighbors.
```{r}
cancer_test_pred <- knn(train = cancer_train, test = cancer_test,
                        cl = cancer_train_labels, k = 21)
```
The ´r knn()´ function returns a factor vector of predicted labels for each of 
the examples in the ´test´ dataset, which we hace assigned to ´cancer_test_pred´.


# Step 4

## Evaluating model performance

We have to evaluate how well the predicted classes in the ´cancer_test_pred´ vector
match up with the known values in the ´cancer_test_labels´ vector. From these
we can use the ´CrossTable()´ function.
```{r}
#install.packages("gmodels")
library("gmodels")
```
We can create a cross tabulation indicating the agreement between the two vectors.
Specifiying ´r prop.chisq = FALSE´ will remove the unnecessary chi-square values
from the output
```{r}
CrossTable(x=cancer_test_lables, y=cancer_test_pred, prop.chisq = FALSE)
```
The cell percentages in the table indicate the proportion of values that fall 
into four categories.

The tip-left cell indicates the **true negative** results. These 61 of 100 values
are cases where the mass was benign and the k-NN algorithm correctly identified
it such. 

The bottom-right cell indicates the **true positive** results, where the
classifier and the clinically determined label agree that mass is malignant. A
total of 37 of 100 predictions were true positives.

The cells falling on the other diagonal contain counts of examples wher-left cell
are **false negative** results; in this case, the predicted value was benign, but 
the tumor was actually malignant.

The top-right cell would contain the **false positive** results if there were 
any. Model classifies a mass as malignant, but in reality it was benign.

A 98 percent accuracy seems very good, we might try another iteration of the
model to see whether we can improve the performance and reduce the number of 
values that have been incorrectly classified, particularly because the errors 
were dangerous false negatives.

# Step 5

## Improving model performance

We will attempt two simple variations on our previous classifier. First, we will
employ an alternative method for rescaling our numeric features. Second, we will
try several different values for *k*.

## Transformation - z-score standardization

The z-score standardized values have no predefined minimun and maximum, extreme 
values are not compressed towards the center. One might suspect that with a 
malignant tumor, we might see some very extreme outliers as the tumors grow 
uncontrollably. It might, therefore, be reasonable to allow the outliers to be 
weighted more heavily in the distance calculation. 

Let´s see whether z-score standardization can improve our predictive accuracy.

To standardize a vector, we can use the ´r scale()´ function, which rescales 
values using the z-score standardization. The ´r scale()´ function offers the
additional benefit that it can be applied directly to a data frame, so we can
avoid the use of the ´r lapply()´ function. 
```{r}
cancer_z <- as.data.frame(scale(cancer_mama[-1]))
```

This command rescales all the features, with the exception of ´diagnosis´ and 
stores the result as the ´cancer_z´ dataframe. 

Check the transformation
```{r}
summary(cancer_z$area_mean)
```

The mean of a z-score standardized variable should always be zero, and the range
should ne fairly compact. A z-score greater than 3 or less than -3 indicates an
extremely rare value. With this in mind, the trasformation seems to have worked.

As we had done earlier, we need to divide the data into training and test sets, 
and the classify the test instances using the ´r knn()´ function. We´ll then 
compare the predicted labels to the actual labels using ´r CrossTable()´
```{r}
cancer_z_train <- cancer_z[1:469, ]
cancer_z_test <- cancer_z[470:569, ]
```

```{r}
cancer_z_test_pred <- knn(train = cancer_z_train, test = cancer_z_test,
                          cl= cancer_train_labels, k = 21)
```

```{r}
CrossTable(x= cancer_test_lables, y=cancer_z_test_pred,
           prop.chisq = FALSE)
```
the results of the new transformation show a slight decline in accuracy. The 
instances where we had correctly classified 98 percent of examples previously,
we classified only 95 percent correctly this time. Also, we have more **false negative**
so we didn´t better at classifying the dangerous false negatives.

## Testing alternative values of k








