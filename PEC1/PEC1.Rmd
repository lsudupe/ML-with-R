---
title: "PEC1: Algorithm K-NN"
author: "Laura Sudupe Medinilla"
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
output:
  pdf_document:
    toc: TRUE
  html_document:
    toc: TRUE
knit: rmarkdown::render("PEC1.Rmd", c("pdf_document", "html_document"),output_file = c("PEC1.pdf","PEC1.html"))
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NULL)
```

```{r load_libraries, include=FALSE}
require(knitr)
require(class)
require(caret)
require(caTools)
require(gmodels)
require(base)
require(data.table)
require(ROCR)
```


```{r asignaciones, include=FALSE}
myfile <-"data4.csv"
```


# The kNN Algorithm

In this markdown we are going to learn about classification using k-NN. Unlike
many classification algorithms, k-NN does not do any learning. It simply stores 
the training data verbatim. Unlabeled test examples are then matched to the most 
similar records in the training set usin a distance function, and the unlabeled
example is assignaed the label of its neighbors.

The strengths and weaknesses of this algorithm are as follows:

| **Strengths**    | **Weaknesses**  | 
| ------------------------ |:------------------------------------------------------- |
|* Simple and effective     |* Does not produce a model, which limits the ability to find novel insights in relationships among features |
| * Makes no assumptions about the underlying data distribution | * Slow classification phase |
| * Fast training phase | * Requires a large amount of memory  
|    | * Nominal features and missing data require additional processing |



# Step 1 - Collecting data

We will utilize the "Protein Secondary Structure" from the Brookhaven National Laboratory (USA).This data includes the protein secondary structures from 101 representative proteins.

```{r data, include=FALSE}
amino <- read.csv("data4.csv", head=TRUE, sep= ";")
amino_one_hot <- read.csv("oh_enc.csv", stringsAsFactors = FALSE)
```


# Step 2 - Exploring and preparing the data

We are going to take a look to our data with `str(amino)`. 
```{r, echo=FALSE}
str(amino, list.len=6)
```
The data is structured with `r nrow(amino)` sequences with `r ncol(amino)` amino acids. We want to see which is the central amino acid structure type. The `table()` output indicates that `r as.numeric(table(amino$V18))[1]` aminos has **coil** structure, `r as.numeric(table(amino$V18))[2]` has **beta-sheet** structure and `r as.numeric(table(amino$V18))[3]` has **alpha-helix** structure.

```{r}
table(amino$V18)
```
We can label the data and check the structure porcentages with `prop.table()`
```{r}
amino$V18 <- factor(amino$V18, levels = c("_", "e", "h"),
              labels=c("coil","beta-sheet","alpha-sheet"))
round(prop.table(table(amino$V18)) * 100, digits = 1)
```

## Creating training and test datasets

We are going to divide our data into two portions: a training dataset that will be used to build the KNN model and a test dataset that will be used to estimate the predictive accuracy of the model. We will use 67% of the data for training and 33% for testing. The `sample ()` function select aleatory 67% of the rows (`r nrow(amino_one_hot)`).

```{r}

data <- cbind(amino_one_hot, amino[,ncol(amino)])
colnames(data)[ncol(data)] <- 'V341'

set.seed(123)

train_indx <- sample(x= 1:nrow(data),
                     size= 0.67*nrow(data),
                     replace=FALSE)

train_data <- data[train_indx,-ncol(data)]
test_data <- data[-train_indx,-ncol(data)]

train_label <- data[train_indx, ncol(data)]
test_label <- data[-train_indx, ncol(data)]

```


# Step 3 - Training a model on the data

For the classification, we will use a kNN implementation from the `class` package. We use the `knn()` function to classify the test data
```{r}
amino_test_pred <- knn(train= train_data, test= test_data,
                       cl=train_label, k=21)

```

The `knn()` function returns a factor vector of predicted labels for each of the examples in the test dataset, which we have assigned to `amino_test_pred`.


# Step 4 - Evaluating model performance

We need to evaluate how well the predicted classes in the `amino_test_pred` vector match up with the known values in the `test_label` vector.
To these purpose, we can use the `CrossTable()` function. We will create a cross tabulation indicating the agreement between two vectors.


```{r}
CrossTable(x=test_label, y=amino_test_pred, prop.chisq=FALSE)
```

```{r}
table_knn <- table(amino_test_pred, test_label)
table_knn

```

The cell percentage in the table indicate the portion of values that fall into four categories. In the top-left, these `r table_knn[1,1]` are the number of values that KNN algorithm correctly identified as coil. In the diagonal we have the true positive values, for example, `r table_knn[3,3]` shows the values KNN correctly identified as alpha-sheet. In despite of these, `r table_knn[2,1]` are false negatives, the predicted values werebeta-sheet but the structure was coil. 

On the other side, a total of `r table_knn[3,1]` were incorrectly classified by the KNN algorithm like alpha-sheet.



# Step 5 - Improving the model performance

We will try several different values for **k**, (k = 1, 3, 5, 7, 11), to examine the performance. Using the previous test and training datasets, the same  records were classified. The number of false negatives and false positives are shown for each iteration.

```{r, include=FALSE}

ks <- c(1, 3, 5, 7, 11)
resum <- data.frame(ks, FN=NA, FP=NA, mal_clas=NA)

j <- 0
for (i in ks){
  j <- j +1
  amino_test_pred <- knn(train = train_data, test = test_data, cl = train_label, k=i)
  conf.mat <- CrossTable(x = test_label, y = amino_test_pred, prop.chisq=FALSE)
  
  resum[j,2:4] <- c(conf.mat$t[2,1], conf.mat$t[1,2], ((conf.mat$t[1,2]+conf.mat$t[2,1])/sum(conf.mat$t))*100)
}

```

```{r, echo=FALSE}
kable(resum, col.names=c("k value", "# false negatives", 
      "# false positives", "% classified Incorrectly"),
      align= c("l","c","c","c"))
```

The 11NN aproach was able yo avoid a lot of false positives at the expense of adding false negatives. In these cases, the 1NN aproach has the higher porcentage os classified incorrectly.

Let's see some other values

```{r}
confusionMatrix(amino_test_pred, test_label, positive = "coil" )
```

The kappa value adjusts accuracy by acounting for the possibility of a correct prediction by chance alone. We have a fair agreement kappa value, and big error rate, these indicated us the proportion of the incorrectly classified examples.


# Step 7 - Prove our KNN classifier with different labels


We know the alpha-helix and beta-sheet are both non-coil structures. We are going to performe the same algorithm for these labels.

```{r}
data_coil <- cbind(amino_one_hot, amino[,ncol(amino)])
colnames(data_coil)[ncol(data_coil)] <- 'V341'

data_coil$V341 <- factor(data_coil$V341, levels = c( "beta-sheet", "alpha-sheet", "coil"),
              labels=c("no-coil","no-coil","coil"))

```


```{r}
table(data_coil$V341)
```


## Creating training and test datasets

We are going to divide our data into two portions: a training dataset that will be used to build the KNN model and a test dataset that will be used to estimate the predictive accuracy of the model. 


```{r}
train_indx_coil <- sample(x= 1:nrow(data_coil),
                     size= 0.67*nrow(data_coil),
                     replace=FALSE)

train_data_coil <- data_coil[train_indx_coil,-ncol(data_coil)]
test_data_coil <- data_coil[-train_indx_coil,-ncol(data_coil)]


train_label_coil <- data_coil[train_indx_coil, ncol(data_coil)]
test_label_coil <- data_coil[-train_indx_coil, ncol(data_coil)]


```


The Receiver Operating Characteristic curve is used to examine the trade-off between the detection of true positives, whiile avoiding the false positives. we are goint to calculate de AUC from all the k-s


```{r}

# ROC and AUC for k=1
aminocoil_test_pred1 <- knn(train = train_data_coil, test = test_data_coil, cl = train_label_coil, k=1,prob = TRUE)
prob1 <- attr(aminocoil_test_pred1, "prob")
prob1 <- ifelse(aminocoil_test_pred1 == "coil", 1-prob1, prob1) - 1
labels1 <- factor(test_label_coil, labels = c(0,1))

roc1 <- pROC::roc(labels1, prob1, auc= TRUE, ci=TRUE)

# ROC and AUC for k=3
aminocoil_test_pred3 <- knn(train = train_data_coil, test = test_data_coil, cl = train_label_coil, k=3,prob = TRUE)
prob3 <- attr(aminocoil_test_pred3, "prob")
prob3 <- ifelse(aminocoil_test_pred3 == "coil", 1-prob3, prob3) - 1
labels3 <- factor(test_label_coil, labels = c(0,1))

roc3 <- pROC::roc(labels3, prob3, auc= TRUE, ci=TRUE)

# ROC and AUC for k=5
aminocoil_test_pred5 <- knn(train = train_data_coil, test = test_data_coil, cl = train_label_coil, k=5,prob = TRUE)
prob5 <- attr(aminocoil_test_pred5, "prob")
prob5 <- ifelse(aminocoil_test_pred5 == "coil", 1-prob5, prob5) - 1
labels5 <- factor(test_label_coil, labels = c(0,1))

roc5 <- pROC::roc(labels5, prob5, auc= TRUE, ci=TRUE)

# ROC and AUC for k=7
aminocoil_test_pred7 <- knn(train = train_data_coil, test = test_data_coil, cl = train_label_coil, k=7,prob = TRUE)
prob7 <- attr(aminocoil_test_pred7, "prob")
prob7 <- ifelse(aminocoil_test_pred7 == "coil", 1-prob7, prob7) - 1
labels7 <- factor(test_label_coil, labels = c(0,1))

roc7 <- pROC::roc(labels7, prob7, auc= TRUE, ci=TRUE)

# ROC and AUC for k=11
aminocoil_test_pred11 <- knn(train = train_data_coil, test = test_data_coil, cl = train_label_coil, k=11,prob = TRUE)
prob11 <- attr(aminocoil_test_pred11, "prob")
prob11 <- ifelse(aminocoil_test_pred11 == "coil", 1-prob11, prob11) - 1
labels11 <- factor(test_label_coil, labels = c(0,1))

roc11 <- pROC::roc(labels11, prob11, auc= TRUE, ci=TRUE)




```
```{r, echo=FALSE}
#ROC plots

par(mfrow=c(2,3))
pROC::plot.roc( roc1, legacy.axes = TRUE, print.thres = "best", print.auc = TRUE,
          auc.polygon = FALSE, max.auc.polygon = FALSE, auc.polygon.col="gainsboro",
          col = 2, grid = TRUE , main= "ROC with k=1")

pROC::plot.roc( roc3, legacy.axes = TRUE, print.thres = "best", print.auc = TRUE,
          auc.polygon = FALSE, max.auc.polygon = FALSE, auc.polygon.col="gainsboro",
          col = 2, grid = TRUE, main= "ROC with k=3" )

pROC::plot.roc( roc5, legacy.axes = TRUE, print.thres = "best", print.auc = TRUE,
          auc.polygon = FALSE, max.auc.polygon = FALSE, auc.polygon.col="gainsboro",
          col = 2, grid = TRUE, main= "ROC with k=5" )

pROC::plot.roc( roc7, legacy.axes = TRUE, print.thres = "best", print.auc = TRUE,
          auc.polygon = FALSE, max.auc.polygon = FALSE, auc.polygon.col="gainsboro",
          col = 2, grid = TRUE,  main= "ROC with k=7")

pROC::plot.roc( roc11, legacy.axes = TRUE, print.thres = "best", print.auc = TRUE,
          auc.polygon = FALSE, max.auc.polygon = FALSE, auc.polygon.col="gainsboro",
          col = 2, grid = TRUE, , main= "ROC with k=11" )

```

The perfect classifier has a curve that passes through the point at a 100 percent true positive rate and 0 percent false positive rate. The closer the curve is to the perfect classifier, the better it is at identifying positive values. This measured using a statistic known as the *area under the ROC curve* (abbreviated *AUC*). The best AUC value it was 1NN classifier, next 3NN and the others are similar between them.





```{r, include=FALSE}

ks2 <- c(1, 3, 5, 7, 11)
resum2 <- data.frame(ks, FN=NA, FP=NA, mal_clas=NA)

j <- 0
for (i in ks2){
  j <- j +1
  amino_test_pred <- knn(train = train_data_coil, test = test_data_coil, cl = train_label_coil, k=i)
  conf.mat <- CrossTable(x = test_label_coil, y = amino_test_pred, prop.chisq=FALSE)
  
  resum2[j,2:4] <- c(conf.mat$t[2,1], conf.mat$t[1,2], ((conf.mat$t[1,2]+conf.mat$t[2,1])/sum(conf.mat$t))*100)
}

```


```{r, echo=FALSE}
kable(resum2, col.names=c("k value", "# false negatives", 
      "# false positives", "% classified Incorrectly"),
      align= c("l","c","c","c"))

```
The best classifier is 1NN , these it is reflected with the AUC value before. 

# Conclusion

We observe that in both cases the 1NN has been the one with the best predictions, we see that as we increase the closest neighbors, the false positives and negatives as expected. The ROC curve and the AUC value serve to reaffirm the results obtained by the performance evaluation



















