---
title: "PEC1: Algorithm K-NN"
author: "Laura Sudupe Medinilla"
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
output:
  pdf_document:
    toc: TRUE
  html_document:
    toc: TRUE
knit: rmarkdown::render("PEC1: Algorithm K-NN", c("pdf_document", "html_document"),output_file = c("PEC1: Algorithm K-NN","PEC1: Algorithm K-NN"))
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NULL)
```

```{r load_libraries, include=FALSE}
require(knitr)
require(class)
```

# The kNN Algorithm

In this markdown we are going to learn about classification using k-NN. Unlike
many classification algorithms, k-NN does not do any learning. It simply stores 
the training data verbatim. Unlabeled test examples are then matched to the most 
similar records in the training set usin a distance function, and the unlabeled
example is assignaed the label of its neighbors.

The strengths and weaknesses of this algorithm are as follows:

| **Strengths**    | **Weaknesses**  | 
| ------------------------ |:------------------------------------------------------- |
|* Simple and effective     |* Does not produce a model, which limits the ability to find novel insights in relationships among features |
| * Makes no assumptions about the underlying data distribution | * Slow classification phase |
| * Fast training phase | * Requires a large amount of memory  
|    | * Nominal features and missing data require additional processing |



# Step 1 - Collecting data

We will utilize the "Protein Secondary Structure" from the Brookhaven National Laboratory (USA).This data includes the protein secondary structures from 101 representative proteins.


```{r data, include=FALSE}
amino <- read.csv("data4.csv", head=TRUE, sep= ";")
amino_one_hot <- read.csv("oh_enc.csv", stringsAsFactors = FALSE)
```


# Step 2 - Exploring and preparing the data

We are going to take a look to our data with `str(amino)`. 
```{r, echo=FALSE}
str(amino, list.len=6)
```
The data is structured with `r nrow(amino)` sequences with `r ncol(amino)` amino acids. We want to see which is the central amino acid structure type. The `table()` output indicates that `r as.numeric(table(amino$V18))[1]` aminos has **coil** structure, `r as.numeric(table(amino$V18))[2]` has **beta-sheet** structure and `r as.numeric(table(amino$V18))[3]` has **alpha-helix** structure.

```{r}
table(amino$V18)
```
We can label the data and check the structure porcentages with `prop.table()`
```{r}
amino$V18 <- factor(amino$V18, levels = c("_", "e", "h"),
              labels=c("coil","beta-sheet","alpha-sheet"))
round(prop.table(table(amino$V18)) * 100, digits = 1)
```
## Data preparation 

### One-hot transformation 

### Creating training and test datasets

We are going to divide our data into two portions: a training dataset that will be used to build the KNN model and a test dataset that will be used to estimate the predictive accuracy of the model. 
```{r}
#create training and test data
amino_train <- amino_one_hot[1:6700, ]
amino_test <- amino_one_hot[6701:10000, ]
```








# Step 3 - Training a model on the data

# Step 4 - Evaluating model performance

# 







