---
title: 'Classification and diagnostic rpediction of cancers using gene expression profiling and artificial neural networks'
author: Laura Sudupe Medinilla
subtitle: '`r params$subtitulo`'
date: '`r format(Sys.Date(),"%e de %B, %Y")`' 
# date: \today  (solo para pdf)
output:
  pdf_document:
    keep_tex: yes
    toc: yes
    df_print: kable
    highlight: zenburn
  html_document:
    df_print: paged
    toc: yes
    toc_float: true
    theme: united
    highlight: tango
  html_notebook:
    df_print: paged
    toc: yes
    toc_float: true
    theme: united
    highlight: tango
header-includes:
  - \usepackage[spanish]{babel}
params:
  file: pcaComponents7.csv
  p.train: 0.6666667
  subtitulo: PEC2
  seed.train: 12345
  seed.clsfier: 1234567
---

```{r setup, include=FALSE}
#With this chunck when we run the scripts it creates folders to save the results. When we run again the script only run the changed code. Good option when our script has a high computational cost
knitr::opts_chunk$set(echo = TRUE, comment = NULL, cache=TRUE)
options(width=90)
```


```{r packages, message=FALSE, echo=FALSE, warning=FALSE}
libraries <- c("ggplot2" ,"caret", "e1071", "kernlab")
check.libraries <- is.element(libraries, installed.packages()[, 1])==FALSE
libraries.to.install <- libraries[check.libraries]
if (length(libraries.to.install!=0)) {
  install.packages(libraries.to.install)
}

success <- sapply(libraries,require, quietly = FALSE,  character.only = TRUE)
if(length(success) != length(libraries)) {stop("A package failed to return a success in require() function.")}
```



# Objetive

In this PEC we are going to do a dinamic report where we are going to analize an experiment related with the prediction of four different cancer types and healthy patients.
For these purpose, we are going to analize the data with the implementation of two different algorithms: `Artificial Neural Network` and `Support Vector Machine` to predict the type.



# Introduction

The first and second step are the same for both algorithms so we are going to do them in the first place. After this, we are going to explain briefly both algorithms.We are going to add a table with their strenghs and weaknesess to understand better the posibilities. Inside the algorithmns part, we are going to process with three different steps:

- Model training with the data
- Model performance evaluation
- Model improvement

In both cases, we are going to analyze the algorithms quality and performance with the `confusionMatrix()` function from **caret** package. At the end, we are going to add a conclusion and discussion section.


## Step 1 - Collecting the data 



Importamos el fichero "promoters.txt" que se nos proporciona y el cual contiene en la primera columna el simbolo indicando la clase (+ = promotor); en la segunda columna el nombre de la secuencia promotora, denominandose las instancias que corresponden a no promotores por la posicion genomica; y en la tercera columna los 57 nucleotidos de cada secuencia.
Importamos tambien el fichero `promoters_onehot` que ya contiene las secuencias codificadas segun un one-hot, pero tan solo se utilizara como comprobacion de resultados. 

```{r, echo=FALSE}
# import the csv

file <- "pcaComponents7.csv"
file2 <- "class7.csv"
pca_comp <- read.csv(file, header=TRUE)
pca_10comp <- pca_comp[,1:10]

tumor_type <- read.csv(file2, header=TRUE)

data <- cbind.data.frame(pca_10comp, tumor_type)


```

## Step 2- Exploring and preparing the data 

Usando el comando `str()`, observamos que el conjunto de datos promoters contiene `r nrow(promoters)` filas, que corresponden a las secuencias y `r ncol(promoters)` columnas, como mencionabamos previamente.  Las primeras 6 lineas del output son: 

```{r}
# examinando la estructura del dataset
str(data)
```

Ya que muchos clasificadores de machine learning necesitan que la caracteristica diana sea codificada como factor, lo primero que tenemos que hacer es comprobar si la variable `V1`, que corresponde a la clase, es un factor. Esta variable corresponde a la primera columna del data frame `promoters` y que como deciamos previamente contiene el simbolo + si es un promotor o el simbolo - si no lo es. No lo es, por lo que lo codificamos:

```{r}
#llamaremos P a las secuencias promotoras y NP a las no promotoras
data$x <- factor(data$x, levels = c(1,2,3,4),
                         labels = c("ALL", "AML", "CML", "NoL"))
#llamamos clase a la columna V1
names(data)[11] <- "type"
```

Comprobamos:

```{r}
class(data$type)
```
Podemos observar cuantas secuencias son promotoras o no promotoras en este data frame:

```{r}
table(data$type)
```
Y las propociones:

```{r}
round(prop.table(table(promoters$clase)) * 100, digits = 1)
```

Podemos ver que 49.5% de las secuencias no son promotores, mientras que el 50.5% restante si lo son.


### Transformacion - Normalization

Para implementar una transformacion one-hot encoding de las secuencias del fichero de datos `promoters`, generamos la funcion `hot_enc()` en R:

```{r}
normalize <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}

data_nrm <- as.data.frame(lapply(data[,-11],normalize))

```

Y ahora utilizamos dicha funcion en el data frame `promoters`, y al vector final le llamaremos `onehot_encoding`

```{r}
hot_enc(promoters) -> onehot_encoding
#las dimensiones de este vector deben ser 105 filas (numero de secuencias) y 228 columnas (57 nucleotidos en cada secuencia y cada uno genera un vector de 4 bit)
#convertimos los valores numericos en valores enteros
onehot_encoding <- data.frame(onehot_encoding)
onehot_encoding <- lapply(onehot_encoding, as.integer)
onehot_encoding <- data.frame(onehot_encoding)
```

```{r, echo=FALSE}
write.csv(onehot_encoding, "onehot_encoding.csv", quote = FALSE, row.names = FALSE)
```

Ahora eliminamos la tercera columna del data frame `promoters` y unimos las 2 columnas restantes con el data frame `onehot_encoding`, generando uno nuevo llamado `promoters_enconding`

```{r}
promoters_encoding <- cbind(promoters[,1:2], onehot_encoding)
```

Utilizamos de nuevo el comando `str()` y observamos que ahora el conjunto de datos `promoters_enconding` contiene las mismas filas que antes: `r nrow(promoters_encoding)`, pero `r ncol(promoters_encoding)` columnas.  Las primeras 6 lineas del output son: 

```{r}
# examinando la estructura de los datasets impensData y schillingData
str(promoters_encoding, list.len=6)
```

Comprobamos si el data frame `promoters_enconding` generado gracias a la funcion implementada en `promoters` es igual al data frame que se nos proporcionaba en el enunciado ya con el one-hot encoding realizado (`promoters_onehot`)

```{r}
str(promoters_onehot, list.len=6)
```

Observamos que tanto el numero de filas y de columnas, como el tipo de variables (salvo la variable class que no ha sido codificada aun como factor) y los valores son iguales. Por lo tanto, a partir de ahora, podemos utilizar cualquier de los dos data frames. Yo utilizare `promoters_enconding`

El identificador no lo necesitamos para nada, por lo que lo eliminamos:

```{r}
promoters_encoding <- promoters_encoding[,-2]
```

### Binary variable creation instead of the factor class variables

La funcion `neuralnet()` que utilizaremos para el algoritmo de redes neuronales artificiales, no admite variables factor o categoricas. Por tanto, hay que transformar la variable `clase` que indica el tipo de secuencia  (promotora o no promotra) a binaria. Para este cometido, se deben crear dos variables que sustituyen a la variable original. Una sera la variable promotor (P) que tiene valores (TRUE o 1) en los casos P y (FALSE o 0) en los casos NP. De manera semejante, se crea la variable no promotor (NP). 

Ahora se crean tantas variables binarias como categorias tiene la variable `clase`. 


```{r}
# Creacion de variables binarias a partir de la variable factor
promoters_encoding$P <- promoters_encoding$clase=="P"
promoters_encoding$NP <- promoters_encoding$clase=="NP"
```


### Creating training and test datasets

Para generar los conjuntos de datos, utilizamos el data frame `promoters_encoding`, en el que cada fila es una secuencia de nucleotidos, y el orden es el mismo que el establecido en el data frame `promoters`

Dividimos en dos partes `promoters_encoding`: un conjunto de datos de training `data_train`, que se utiliza para construir los diferentes modelos; y un conjunto de datos de testing `data_test` que se utiliza para estimar la precision predictiva de los modelos. 

Utilizaremos el 67% de los datos para training y el 33% para testing. La seleccion de cada muestra se realiza de manera aleatoria, utilizando el valor de la semilla = 123, lo que nos permite reproducir mas tarde estos mismos data frames que se van a originar de manera aleatoria. En el data frame `sample_train`, la funcion `sample ()` selecciona, al azar, el 67% del total de filas (`r nrow(onehot_encoding)`)

```{r}
set.seed(123)
sample_train <- sample(nrow(promoters_encoding), nrow(promoters_encoding) * 0.67)
str(sample_train)
```

Como podemos observar, el objeto `sample_train` es un vector de 70 numeros enteros aleatorios.

Utilizando este vector, seleccionamos las filas de los datos de `promoters_encoding` y los dividimos en los conjuntos de datos `data_train` del 67% y `data_test` del 33%.

```{r}
data_train <- promoters_encoding[sample_train, ]
# al utilizar el operador minus previo a sample_train al generar la muestra de testing, le decimos a R que seleccione los registros que no estan en las filas especificadas; es decir, los datos de testing incluyen solo las filas que no estan en la muestra de training.
data_test <- promoters_encoding[-sample_train, ]

# Creo dos vectores con las clases, es decir, la columna 1 del data frame promoters_encoding en el cual aparece P o NP de acuerdo a si la secuencia de nucleotidos era promotor o no 
vector <- promoters_encoding[, 1]
data_train_labels <- vector[sample_train]
data_test_labels <- vector[-sample_train]
```

Como podemos observar, el objeto `data_train` es un data frame de `r nrow(data_train)` secuencias aleatorias con codificacion one-hot, mientras que `data_test` contiene las otras `r nrow(data_test)` secuencias.



# Neural Networks algorithm (ANN)

# Naive Bayes Algorithm 

The *Artificial Neural Network (ANN)* models the relationship between a set of input signals and an output signal using a model derived from our understanding of how a biological brain responds to stimuli from sensory inputs. Just as a brain uses a network of interconnected cells called neurons to create a massive parallel processor, ANN uses a network of artificial neurons or nodes to solve learning problems. 


| **Strenghts**    | **Weaknesses**  | 
| ----------------------------- |:------------------------------------------- |
| * Can be adapted to classification or numeric prediction problems | * Extremely computationally intensive and slow to train, particularly if the network topology is complex|
| * Capable of modeling more complex patterns than nearly any algorithm  |  *Very prone to overfitting training data |
| * Makes few assumptions about the data's underlying relationships  | * Results in a complex black box model that is difficult, if not impossible, to interpret |  |



## Step 3 - Training a model on the data

Las redes neuronales funcionan mejor cuando los datos de entrada se escalan a un rango estrecho alrededor de cero. Puesto que en este caso tan solo tenemos valores de 0 o 1, no es necesario normalizar.

Para la construccion de la red neuronal artificial se usa la funcion `neuralnet()` del paquete *neuralnet*. Como mencionabamos previamente, esta funcion no admite variables factor o categoricas, por lo que creamos las dos variables: P, que tiene valores (TRUE o 1) en los casos P y (FALSE o 0) en los casos NP. De manera semejante, se crea la variable NP. Esta funcion admite variables logicas (TRUE/FALSE) y las transforma a binarias internamente. 

Al crear dos variables binarias como variables a predecir la red neuronal tendra 2 nodos de output.

La formula del modelo tiene 228 nodos de entrada (resultado de la codificacion one-hot de cada nucleotido) y 2 nodos de salida:

```{r}
## creamos una formula para un modelo con un gran numero de variables
xnam <- names(promoters_encoding[,2:229])
(fmla <- as.formula(paste("P + NP ~ ", paste(xnam, collapse= "+"))))
```

Entrenamos una red multicapa con cuatro nodos ocultos, a la que llamaremos `ANN4`, y examinamos su topologia

```{r}
set.seed(123)
ANN4  <- neuralnet(fmla,data_train[-1],hidden=4,linear.output=FALSE)
```

```{r}
# representamos graficamente el modelo generado
plot(ANN4,rep="best")  
```

Ahora se representa el mismo modelo usando el paquete *NeuralNetTools*:

```{r}
plotnet(ANN4, alpha = 0.6)
```

## Step 4 - Evaluating model performance

Una vez obtenido el modelo, se procede a clasificar las muestras test con la funcion `compute`, la cual devuelve una lista con dos componentes: "neurons", que almacena los nodos para cada capa en la red y "net.result", que almacena los valores predichos. Queremos esto ultimo.

Para la red neuronal `ANN4`:

```{r}
ANN4_results <- neuralnet::compute(ANN4, data_test[,2:229])$net.result
# Funcion para transformar un output binario multiple en categorico
maxidx <- function(arr) {
  return(which(arr == max(arr)))
}

idx_4 <- apply(ANN4_results, 1, maxidx)
prediction_4 <- c('P', 'NP')[idx_4]
res_4 <- table(prediction_4, data_test_labels)
res_4 <- res_4[c("P","NP"),]
(matrix <- confusionMatrix(res_4,positive="P"))
```

Utilizando una red neuronal de cuatro capas ocultas con categoria positiva 'P', de un total de `r sum(matrix$t)`, hay `r matrix$t[1,1]` verdaderos positivos, `r matrix$t[2,2]` verdaderos negativos, `r matrix$t[2,1]` falsos negativos  y `r matrix$t[1,2]` falsos positivos.  Este algoritmo, por tanto, consigue una precision de `r round(matrix$overall["Accuracy"], 3)` y un estadístico kappa de `r round(matrix$overall["Kappa"], 7)`. Los valores de sensibilidad y especificidad son de 0.8824 y 1, respectivamente. Este algoritmo clasifica bien 33 de 35 secuencias, mientras que el numero de falsos negativos (2) es mayor que el de falsos positivos, puesto que no hay. 

## Step 5 - Model improvement

Para observar si hay una mejora, probaremos a implementar una red neuronal de cinco capas ocultas.  Llamaremos al clasificador `ANN5`:

```{r}
set.seed(123)
ANN5 <- neuralnet(fmla,data_train[-1],hidden=5,linear.output=FALSE)
plot(ANN5, rep="best")
```

Ahora se representa el mismo modelo usando el paquete *NeuralNetTools*:

```{r}
plotnet(ANN5, alpha = 0.6)
```

Una vez obtenidos los modelos, se procede a clasificar las muestras test con la funcion `compute`, de la cual queremos los "net.result", que almacenan los valores predichos:

```{r}
ANN5_results <- neuralnet::compute(ANN5, data_test[,2:229])$net.result

maxidx <- function(arr) {
  return(which(arr == max(arr)))
}

idx_5 <- apply(ANN5_results, 1, maxidx)
prediction_5 <- c('P', 'NP')[idx_5]
res_5 <- table(prediction_5, data_test_labels)
res_5 <- res_5[c("P","NP"),]
(matrix5 <- confusionMatrix(res_5,positive="P"))
```

Utilizando una red neuronal de cinco capas ocultas con categoria positiva 'P', de un total de `r sum(matrix5$t)`, hay `r matrix5$t[1,1]` verdaderos positivos, `r matrix5$t[2,2]` verdaderos negativos, `r matrix5$t[2,1]` falsos negativos  y `r matrix5$t[1,2]` falsos positivos.  Este algoritmo, por tanto, consigue una precision de `r round(matrix5$overall["Accuracy"], 3)` y un estadístico kappa de `r round(matrix5$overall["Kappa"], 7)`. Los valores de sensibilidad y especificidad son de 0.8235 y 0.8889, respectivamente. Este algoritmo clasifica bien 30 de 35 secuencias, mientras que el numero de falsos negativos (3) es mayor que el de falsos positivos (2). En terminos generales, podemos ver que la red neuronal con cinco capas ocultas parece funcionar peor que la de cuatro capas ocultas.

La red neuronal de cuatro capas ocultas es el mejores clasificador de secuencias promotoras hasta ahora.

# Support Vector Machine (SVM)

A **Support Vector Machine (SVM)** can be imagined as a surface that creates a boundary between points of data plotted in multidimensional that represent examples and their feature values. The goal of a SVM is t create a flat boundary called **hyperplane**, which divides the space to create fairly homogeneus partitions on either side. In this way, the SVM learning combines aspects of both the instance-based nearest neighbor learning and the linear regression modeling. The combination is extremly powerful, allowing SVMs to model highly complex relationships.

| **Strengths**    | **Weaknesses**  | 
| ----------------------------------- |:-----------------------------------|
|- Can be used for classification or numeric prediction problems |- Finding the best model requires testing of various combinations of kernels and model parameters |
| - Not overly influenced by noisy data and not very prone to overfitting | - Can be slow to train, particularly if the input dataset has a large number of features or examples |
| - May be easier to use than neural networks, particularly due to the existence of several well-supported SVM algorithms | - Results in a complex black box model that is difficult, if not impossible, to interpret
| - Gaining popularity due to its high accuracy and high-profile wins in data mining competitions

## Step 3 - Training a model on the data

Utilizaremos la funcion `ksvm()` del paquete `kernlab` para entrenar al modelo SVM, utilizando el dataset `data_train`

Se construye el modelo mas sencillo: lineal usando como kernel el valor `vanilladot`

```{r}
# no utilizaremos las dos ultimas columnas ya que tan solo eran necesarias para el entrenamiento de las redes neuronales
set.seed(123)
lm <- ksvm(clase ~ ., data = data_train[,1:229],kernel = "vanilladot")
lm
```

## Step 4 - Evaluating model performance

La funcion `predict()` nos permite utilizar los modelos de clasificacion previamente generados para hacer predicciones en el dataset de testing `data_test`

```{r}
#la opcion type especifica si la prediccion es "response" (la clase predicha) o "probabilities" (la probabilidad predicha, una columna por nivel de clase)
#por defecto, la funcion predict() tiene type="response"
# no utilizaremos las dos ultimas columnas ya que tan solo eran necesarias para el entrenamiento de las redes neuronales
pre <- predict(lm, data_test[,1:229])
pre
```


```{r}
#la categoria positiva es promotor (P)
cm <- confusionMatrix(pre, data_test_labels, positive = "P")
cm
```

Utilizando un modelo SVM lineal con categoria positiva 'P', de un total de `r sum(cm$t)`, hay `r cm$t[1,1]` verdaderos positivos, `r cm$t[2,2]` verdaderos negativos, `r cm$t[2,1]` falsos negativos  y `r cm$t[1,2]` falsos positivos.  Este algoritmo, por tanto, consigue una precision de `r round(cm$overall["Accuracy"], 3)` y un estadístico kappa de `r round(cm$overall["Kappa"], 7)`. Los valores de sensibilidad y especificidad son de 0.9412 y 0.8333, respectivamente. Este algoritmo clasifica bien 31 de 35 secuencias, mientras que el numero de falsos positivos (3) es mayor que el de falsos negativos (1). 


## Step 5 - Improvement the model

Ahora se plantea SVM con un el kernel Gaussiano, `rbfdot` para tratar de mejorar el rendimiento:

```{r}
set.seed(123)
lm_g <- ksvm(clase ~ ., data = data_train[,1:229], kernel='rbfdot')
lm_g
```

```{r}
pre_g <- predict(lm_g, data_test[,1:229])
pre_g
```

```{r}
#la categoria positiva es promotor (P)
cm_g <- confusionMatrix(pre_g, data_test_labels, positive = "P")
cm_g
```

Utilizando un modelo SVM gausiano con categoria positiva 'P', de un total de `r sum(cm_g$t)`, hay `r cm_g$t[1,1]` verdaderos positivos, `r cm_g$t[2,2]` verdaderos negativos, `r cm_g$t[2,1]` falsos negativos  y `r cm_g$t[1,2]` falsos positivos.  Este algoritmo, por tanto, consigue una precision de `r round(cm_g$overall["Accuracy"], 3)` y un estadístico kappa de `r round(cm_g$overall["Kappa"], 7)`. Los valores de sensibilidad y especificidad son de 0.9412 y 0.9444, respectivamente. Este algoritmo clasifica bien 33 de 35 secuencias, mientras que el numero de falsos positivos y falsos negativos es bajo, tan solo 1 por cada uno. En terminos de eficiencia, el modelo ha mejorado con respecto al SVM lineal, puesto que clasifica bien 2 secuencias mas. Tambien aumenta la especificidad utilizando este algoritmo con respecto al lineal.

En terminos generales, ambos modelos son bastantes eficientes, pero parece que el SVM gausiano funciona mejor con estos datos. 

Hasta ahora, podemos ver que tanto el SVM gausiano como la red neuronal de cuatro capas ocultas obtienen las mejores eficiencias al clasificar las secuencias (promotoras o no). La diferencia entre ellos es que el SVM gausiano obtiene 1 falso negativo y 1 falso positivo, mientras que la red neuronal de cuatro capas ocultas obtiene dos falsos negativos y ningun falso positivo.




# Discusion 

De acuerdo a las matrices de confusion, en las que siempre se ha otorgado a la secuencia promotora la categoria positiva, en general parece estar claro que, si nos centramos en la precision, el algoritmo de clasificacion que mejor funciona para el caso de estudio son los arboles de decision con boosting = 1, ya que la precision es maxima, clasificando en la clase "real" cada secuencia (promotora versus no promotora). Los arboles de decision con boosting=10 tambien obtienen una precision de 1, pero tan solo utilizaron una interaccion, por lo que las otras 9 no fueron necesarias. Tras este, obteniendo una precision de 0.9714, el modelo Random Forests con 100 arboles seria el siguiente mejor clasificador de secuencias. Tras estos dos, con una precision de 0.9429 se encuentran los algoritmos Random Forests con 50 arboles, el SVM gausiano y la red neuronal de 4 capas ocultas. Random Forests con 50 arboles y el SVM gausiano comparten que obtienen 1 falso negativo y 1 falso positivo, mientras que la red neuronal de cuatro capas ocultas obtiene dos falsos negativos y ningun falso positivo. A continuacion, con una precision de 0.9143 aparecen los algoritmos Naive Bayes, tanto con lapalce=0 como con laplace=1, ya que ambos clasifican bien 32 de 35 secuencias, mientras que el numero de falsos negativos es de 2 y el de falsos positivos de 1. Al utilizar el algoritmo SVM lineal se obtiene una precision de 0.8857, que si bien es bastante alta, nos demuestra que en este caso, si tuviesemos que escoger entre los dos SVM utilizados, escogeriamos el SVM gausiano. Lo mismo pasa con las redes neuronales, ya que al utilizar cinco capas ocultas obtenemos una precision de 0.8571, que al comparar con el resultado obtenido al utilizar cuatro capas ocultas nos indica que es mas aconsejable utilizar el modelo con menos capas. Por ultimo, aparecen los algoritmos k-NN, siendo el numero de vecinos utilizados mas optimo, el de 3, puesto que obtenemos una precision de 0.8. Utilizando menos vecinos (k=1), la precision baja a 0.7714, lo mismo que ocurre al aumentar los vecinos (con k=5 obtenemos una precision de 0.7429 y con k=7 de 0.7714).

Con estos datos, podemos afirmar que los algoritmo k-NN son los menos optimos para clasificar secuencias promotoras con los datos del estudio, si bien es cierto que la precision no es extremadamente baja. El resto de clasificadores obtienen una precision bastante alta, pero sin duda, parece que el mejor algoritmo de clasificacion es el de arboles de decision, ya que parecen no cometer ningun error en las predicciones.Por supuesto, harian falta mas medidas de rendimiento para confirmar estos resultados, ya que tan solo con la eficiencia (o incluso con sensibilidad y especificidad) podemos estar perdiendonos informacion esecial y sobrevalorar o infravalorar un clasificador.


