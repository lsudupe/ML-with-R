---
title: 'Neural Networks'
author: Laura Sudupe Medinilla
subtitle: '`r params$subtitulo`'
date: '`r format(Sys.Date(),"%e de %B, %Y")`' 
# date: \today  (solo para pdf)
output:
  html_document:
    df_print: paged
    toc: yes
    toc_float: true
    theme: united
    higlight: tango
  pdf_document:
    keep_tex: yes
    toc: yes
header-includes: \usepackage[spanish]{babel}
params:
  file1: BreastCancer2.csv
  folder.data: ./floweringTime
  p.train: 0.66667
  subtitulo: Predict breast cancer type depending of its biological variables
  valor.seed: 12345
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NULL)
options(width=90)
```


```{r packages, message=FALSE, echo=FALSE, warning=FALSE}
libraries <- c("e1071", "gmodels",  "ROCR", "caret")
check.libraries <- is.element(libraries, installed.packages()[, 1])==FALSE
libraries.to.install <- libraries[check.libraries]
if (length(libraries.to.install!=0)) {
  install.packages(libraries.to.install)
}
library("e1071")
library("gmodels")
library("ROCR")
library("caret")
library("dplyr")
library("neuralnet")

```


\pagebreak

# Naive Bayes Algorithm 

The *Artificial Neural Network (ANN)* models the relationship between a set of input signals and an output signal using a model derived from our understanding of how a biological brain responds to stimuli from sensory inputs. Just as a brain uses a network of interconnected cells called neurons to create a massive parallel processor, ANN uses a network of artificial neurons or nodes to solve learning problems. 


| **Strenghts**    | **Weaknesses**  | 
| ----------------------------- |:------------------------------------------- |
| * Can be adapted to classification or numeric prediction problems | * Extremely computationally intensive and slow to train, particularly if the network topology is complex|
| * Capable of modeling more complex patterns than nearly any algorithm  |  *Very prone to overfitting training data |
| * Makes few assumptions about the data's underlying relationships  | * Results in a complex black box model that is difficult, if not impossible, to interpret |  | 


# Step 1 - Collecting the data

```{r, echo=FALSE}
file1 <- "BreastCancer2.csv"

breast <- read.csv(file1, header=TRUE)

```

This algorithm objetive is to predict the breast cancer type in function of the biological variables `r ncol(breast)` of the cancer. We have this information in the *`r params$file1`* file.


# Step 2 - Exploring and preparing the data

The first step towards constructing our classifier involves processing the raw data for analysis.

Using the `str()` function, we see our data structure

```{r, echo=FALSE}
# examine the structure of R objecte
str(breast)
```

Neural networks work best when the input data are scaled to a narrow range around zero. The solution is to rescale the data with a normalizing or standardization function, in this case, there is normalized to 10

```{r}

normalize <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}

# Aplicamos la normalización a cada columna del dataframe con lapply
breast_norm <- as.data.frame(lapply(breast[-ncol(breast)], normalize))
breast_norm$Class <- breast[,ncol(breast)]

```




## - Creating training and test datasets

We now need to split the data into training which is `r round((p <- params$p.train),2)` and test datasets with the rest. 

```{r}

set.seed(params$valor.seed)
train <- sample(nrow(breast_norm),floor(nrow(breast_norm)*params$p.train))

train_data <- breast_norm[train, ]
test_data <- breast_norm[-train, ]

```

# Step 3 - Training a model on the data

To model the relationship between the biological variables and the cancer type we will use a multilayer feedfoorward neural network. The `neuralnet` package provides a standard and easy-to-use implementation of such networks


```{r}
colnames(breast_norm)
```


```{r}

model_1 <- neuralnet(Class ~ Cl.thickness + Cell.size + Cell.shape + Marg.adhesion + Epith.c.size + Bare.nuclei + Bl.cromatin + Normal.nucleoli +
Mitoses, data = train_data, hidden=1)

```

The function will return a neural network object that can be used to make predictions

We can visualize the network topology using `plot()` function on the resulting model object
```{r}
plot(model_1)
```
In this model, there is one input node for each of the eight features, followed by a single hidden node and a double output nodes that predicts the concrete type of the breast tumor. 

The weights for each of the connections are also depicted, as are the **bias terms**. The bias terms are numeric constants that allow the value at the indicated nodes to be shifted upward or downward, much like the intercept in a linear equation.

A neural network with a single hidden node can be thought of as a distant cousin of the linear regression models. The weight betwee each input node and the hidden node is similar to the regression coefficients, and the weight for the bias term is similar to the intercept. 

Also, we are going to evaluate the model with 3 hidden nodes

```{r}

model_3 <- neuralnet(Class ~ Cl.thickness + Cell.size + Cell.shape + Marg.adhesion + Epith.c.size + Bare.nuclei + Bl.cromatin + Normal.nucleoli +
Mitoses, data = train_data, hidden=3)

plot(model_3)

```


# Step 4 - Evaluatin model performance 

The network topology diagram gives us a peek into the black box of the ANN, but it doesn't provide much information about how well the mdel fits future data. To generate predictions on the dataset, we can use the `compute()` function.


```{r}
model_1_results <- compute(model_1, test_data[1:9])
model_3_results <- compute(model_3, test_data[1:9])
```

This function will return a list with two components, `neurons`, which stores the neurons for each layer in the network, and `net.result` which stores the model's predicted values.

```{r}
test1_pred <- ifelse(model_1_results$net.result[,2] >= 0.5, "malignant", "benign")

test3_pred <- ifelse(model_3_results$net.result[,2] >= 0.5, "malignant", "benign")

```


To compare the predictions to the true values, we´ll use the `CrossTable()` function 
```{r}
par(mfrow=c(1,2))
confusionMatrix(table(test_data$Class, test1_pred), positive = "malignant")
confusionMatrix(table(test_data$Class, test3_pred), positive = "malignant")

```
We have similar results for the condition `hidden = 1` and `hidden = 3`

